{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# COSMOS: å¤šæœºå™¨äººç¼–é˜Ÿå¯¼èˆªæ¼”ç¤º\n\n**COSMOS** (COordinated Safety On Manifold for multi-agent Systems) + RMPflow + MAPPO\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ustbmicl-ros2epucksRL/safe-rl-manifold-suite/blob/master/formation_nav/COSMOS_Demo.ipynb)\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "source": "# @title ç‰ˆæœ¬ä¸æºç é…ç½® { run: \"auto\" }\nfrom datetime import datetime\n\n# Notebook ç‰ˆæœ¬ â€” ç”¨äºæ£€æµ‹ä»“åº“ä¸­æ˜¯å¦æœ‰æ›´æ–°ç‰ˆæœ¬\nNOTEBOOK_VERSION = \"2026-02-23-v2\"\n\n# ----- æºç é…ç½® -----\nGITHUB_ORG = \"ustbmicl-ros2epucksRL\"  # @param {type: \"string\"}\nGITHUB_REPO = \"safe-rl-manifold-suite\"  # @param {type: \"string\"}\nBRANCH = \"master\"  # @param {type: \"string\"}\n\n# ----- å®éªŒé…ç½® -----\nEXPERIMENT_NAME = \"cosmos_exp\"  # @param {type: \"string\"}\nRUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # è‡ªåŠ¨ç”Ÿæˆè¿è¡ŒID\n\nprint(f\"Notebook ç‰ˆæœ¬: {NOTEBOOK_VERSION}\")\nprint(f\"æºç ä»“åº“:      {GITHUB_ORG}/{GITHUB_REPO}\")\nprint(f\"åˆ†æ”¯:          {BRANCH}\")\nprint(f\"å®éªŒåç§°:      {EXPERIMENT_NAME}\")\nprint(f\"è¿è¡ŒID:        {RUN_ID}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–\n",
    "!pip install gymnasium wandb -q\n",
    "\n",
    "# éªŒè¯ç¯å¢ƒ\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. é…ç½® Keys (GitHub & WandB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title é…ç½® API Keys { run: \"auto\" }\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# æ–¹å¼1: ä» Colab Secrets è¯»å– (æ¨è)\n",
    "# åœ¨ Colab å·¦ä¾§ ğŸ”‘ å›¾æ ‡æ·»åŠ  secrets: GITHUB_TOKEN, WANDB_API_KEY\n",
    "try:\n",
    "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "    print(\"âœ“ GitHub Token å·²ä» Secrets åŠ è½½\")\n",
    "except:\n",
    "    GITHUB_TOKEN = None\n",
    "    print(\"âš  GitHub Token æœªè®¾ç½® (å¦‚æœä»“åº“æ˜¯å…¬å¼€çš„åˆ™ä¸éœ€è¦)\")\n",
    "\n",
    "try:\n",
    "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
    "    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n",
    "    print(\"âœ“ WandB API Key å·²ä» Secrets åŠ è½½\")\n",
    "except:\n",
    "    WANDB_API_KEY = None\n",
    "    print(\"âš  WandB API Key æœªè®¾ç½® (å°†ä½¿ç”¨ç¦»çº¿æ¨¡å¼)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹å¼2: æ‰‹åŠ¨è¾“å…¥ (å¦‚æœ Secrets æœªè®¾ç½®)\n",
    "from getpass import getpass\n",
    "\n",
    "if GITHUB_TOKEN is None:\n",
    "    print(\"è¯·è¾“å…¥ GitHub Token (ç•™ç©ºåˆ™å°è¯•å…¬å¼€å…‹éš†):\")\n",
    "    GITHUB_TOKEN = getpass(\"GitHub Token: \") or None\n",
    "\n",
    "if WANDB_API_KEY is None:\n",
    "    print(\"è¯·è¾“å…¥ WandB API Key (ç•™ç©ºåˆ™ä½¿ç”¨ç¦»çº¿æ¨¡å¼):\")\n",
    "    WANDB_API_KEY = getpass(\"WandB API Key: \") or None\n",
    "    if WANDB_API_KEY:\n",
    "        os.environ['WANDB_API_KEY'] = WANDB_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å…‹éš†ä»£ç åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# å…ˆåˆ‡æ¢åˆ° /content ç›®å½•ï¼ˆç¡®ä¿ç›®å½•çŠ¶æ€æ­£å¸¸ï¼‰\n%cd /content\n\n# ä½¿ç”¨é…ç½®çš„ä»“åº“ä¿¡æ¯\nREPO_URL = f\"https://github.com/{GITHUB_ORG}/{GITHUB_REPO}.git\"\nREPO_PATH = f\"/content/{GITHUB_REPO}\"\n\n# æ£€æŸ¥æ˜¯å¦å·²å…‹éš†\nif os.path.exists(REPO_PATH):\n    print(f\"ä»“åº“å·²å­˜åœ¨ï¼Œæ›´æ–°ä»£ç ...\")\n    %cd {REPO_PATH}\n    !git fetch origin\n    !git checkout {BRANCH}\n    !git pull origin {BRANCH}\nelse:\n    # å…‹éš†ä»“åº“ (è·³è¿‡ LFS æ–‡ä»¶ï¼Œå‚è€ƒæ–‡çŒ® PDF ä¸å½±å“ä»£ç è¿è¡Œ)\n    %env GIT_LFS_SKIP_SMUDGE=1\n    if GITHUB_TOKEN:\n        # ä½¿ç”¨ Token å…‹éš†ç§æœ‰ä»“åº“\n        clone_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_ORG}/{GITHUB_REPO}.git\"\n        !git clone -b {BRANCH} {clone_url}\n    else:\n        # å°è¯•å…¬å¼€å…‹éš†\n        !git clone -b {BRANCH} {REPO_URL}\n    \n    %cd {REPO_PATH}\n\nprint(f\"\\nå½“å‰ç›®å½•: {os.getcwd()}\")\nprint(f\"åˆ†æ”¯:     {BRANCH}\")\n!git log --oneline -3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å¯¼å…¥æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import HTML, display\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import time\n",
    "\n",
    "from formation_nav.config import Config\n",
    "from formation_nav.env.formation_env import FormationNavEnv\n",
    "from formation_nav.env.formations import FormationTopology\n",
    "from formation_nav.safety import COSMOS, COSMOSMode\n",
    "from formation_nav.algo.mappo import MAPPO\n",
    "from formation_nav.algo.buffer import RolloutBuffer\n",
    "\n",
    "print(\"âœ“ æ¨¡å—å¯¼å…¥æˆåŠŸ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title è®­ç»ƒå‚æ•° { run: \"auto\" }\n\nNUM_EPISODES = 100  # @param {type: \"slider\", min: 20, max: 500, step: 10}\nNUM_AGENTS = 4  # @param [3, 4, 5, 6] {type: \"raw\"}\nFORMATION = \"square\"  # @param [\"square\", \"triangle\", \"circle\", \"line\", \"hexagon\"]\nSEED = 42  # @param {type: \"integer\"}\n\n# ----- æ—¥å¿—ä¸ä¿å­˜é…ç½® -----\nUSE_WANDB = True  # @param {type: \"boolean\"}\nSAVE_CHECKPOINT_EVERY = 20  # @param {type: \"slider\", min: 10, max: 100, step: 10}\nRESUME_FROM_CHECKPOINT = \"\"  # @param {type: \"string\"}\n\nprint(f\"è®­ç»ƒè½®æ•°:     {NUM_EPISODES}\")\nprint(f\"æ™ºèƒ½ä½“æ•°é‡:   {NUM_AGENTS}\")\nprint(f\"ç¼–é˜Ÿå½¢çŠ¶:     {FORMATION}\")\nprint(f\"éšæœºç§å­:     {SEED}\")\nprint(f\"ä½¿ç”¨ WandB:   {USE_WANDB}\")\nprint(f\"æ£€æŸ¥ç‚¹é—´éš”:   æ¯ {SAVE_CHECKPOINT_EVERY} è½®\")\nprint(f\"æ–­ç‚¹ç»­è®­:     {RESUME_FROM_CHECKPOINT or 'ä»å¤´å¼€å§‹'}\")"
  },
  {
   "cell_type": "code",
   "source": "# @title ç¯å¢ƒå‚æ•° { run: \"auto\" }\n\nARENA_SIZE = 5.0  # @param {type: \"slider\", min: 3.0, max: 10.0, step: 0.5}\nNUM_OBSTACLES = 4  # @param {type: \"slider\", min: 0, max: 8, step: 1}\nMAX_STEPS = 500  # @param {type: \"slider\", min: 100, max: 1000, step: 50}\nDT = 0.02  # @param {type: \"number\"}\nFORMATION_RADIUS = 1.0  # @param {type: \"slider\", min: 0.5, max: 2.0, step: 0.1}\n\nprint(f\"åœºåœ°å¤§å°:   {ARENA_SIZE} x {ARENA_SIZE}\")\nprint(f\"éšœç¢ç‰©æ•°é‡: {NUM_OBSTACLES}\")\nprint(f\"æœ€å¤§æ­¥æ•°:   {MAX_STEPS}\")\nprint(f\"æ—¶é—´æ­¥é•¿:   {DT}\")\nprint(f\"ç¼–é˜ŸåŠå¾„:   {FORMATION_RADIUS}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# @title å®‰å…¨å‚æ•° (COSMOS) { run: \"auto\" }\n\nSAFETY_RADIUS = 0.5  # @param {type: \"slider\", min: 0.2, max: 1.0, step: 0.1}\nBOUNDARY_MARGIN = 0.5  # @param {type: \"slider\", min: 0.1, max: 1.0, step: 0.1}\nCOSMOS_MODE = \"decentralized\"  # @param [\"centralized\", \"decentralized\"]\n\nprint(f\"å®‰å…¨åŠå¾„:     {SAFETY_RADIUS}\")\nprint(f\"è¾¹ç•Œè¾¹è·:     {BOUNDARY_MARGIN}\")\nprint(f\"COSMOS æ¨¡å¼:  {COSMOS_MODE}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# @title ç®—æ³•å‚æ•° (MAPPO) { run: \"auto\" }\n\nLEARNING_RATE = 3e-4  # @param {type: \"number\"}\nPPO_EPOCHS = 10  # @param {type: \"slider\", min: 5, max: 20, step: 1}\nNUM_MINI_BATCH = 4  # @param [2, 4, 8] {type: \"raw\"}\nGAMMA = 0.99  # @param {type: \"slider\", min: 0.9, max: 0.999, step: 0.001}\nGAE_LAMBDA = 0.95  # @param {type: \"slider\", min: 0.9, max: 1.0, step: 0.01}\nCLIP_EPSILON = 0.2  # @param {type: \"slider\", min: 0.1, max: 0.3, step: 0.05}\nENTROPY_COEF = 0.01  # @param {type: \"number\"}\n\nprint(f\"å­¦ä¹ ç‡:       {LEARNING_RATE}\")\nprint(f\"PPO è½®æ•°:     {PPO_EPOCHS}\")\nprint(f\"Mini-batch:   {NUM_MINI_BATCH}\")\nprint(f\"æŠ˜æ‰£å› å­:     {GAMMA}\")\nprint(f\"GAE lambda:   {GAE_LAMBDA}\")\nprint(f\"Clip epsilon: {CLIP_EPSILON}\")\nprint(f\"ç†µç³»æ•°:       {ENTROPY_COEF}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# åˆ›å»ºé…ç½®å¯¹è±¡å’Œè¾“å‡ºç›®å½•\nimport json\n\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# åˆ›å»ºè¾“å‡ºç›®å½•\nOUTPUT_DIR = f\"/content/outputs/{EXPERIMENT_NAME}/{RUN_ID}\"\nCHECKPOINT_DIR = f\"{OUTPUT_DIR}/checkpoints\"\nRESULTS_DIR = f\"{OUTPUT_DIR}/results\"\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\ncfg = Config()\n\n# ç¯å¢ƒé…ç½®\ncfg.env.num_agents = NUM_AGENTS\ncfg.env.formation_shape = FORMATION\ncfg.env.arena_size = ARENA_SIZE\ncfg.env.num_obstacles = NUM_OBSTACLES\ncfg.env.max_steps = MAX_STEPS\ncfg.env.dt = DT\ncfg.env.formation_radius = FORMATION_RADIUS\n\n# å®‰å…¨é…ç½®\ncfg.safety.safety_radius = SAFETY_RADIUS\ncfg.safety.boundary_margin = BOUNDARY_MARGIN\n\n# ç®—æ³•é…ç½®\ncfg.algo.actor_lr = LEARNING_RATE\ncfg.algo.critic_lr = LEARNING_RATE\ncfg.algo.ppo_epochs = PPO_EPOCHS\ncfg.algo.num_mini_batch = NUM_MINI_BATCH\ncfg.algo.gamma = GAMMA\ncfg.algo.gae_lambda = GAE_LAMBDA\ncfg.algo.clip_param = CLIP_EPSILON\ncfg.algo.entropy_coef = ENTROPY_COEF\n\n# è®­ç»ƒé…ç½®\ncfg.train.seed = SEED\n\n# ä¿å­˜é…ç½®åˆ°æ–‡ä»¶\nconfig_dict = {\n    \"experiment_name\": EXPERIMENT_NAME,\n    \"run_id\": RUN_ID,\n    \"num_episodes\": NUM_EPISODES,\n    \"num_agents\": NUM_AGENTS,\n    \"formation\": FORMATION,\n    \"seed\": SEED,\n    \"arena_size\": ARENA_SIZE,\n    \"safety_radius\": SAFETY_RADIUS,\n    \"cosmos_mode\": COSMOS_MODE,\n    \"learning_rate\": LEARNING_RATE,\n    \"device\": DEVICE,\n}\nwith open(f\"{OUTPUT_DIR}/config.json\", \"w\") as f:\n    json.dump(config_dict, f, indent=2)\n\nprint(\"=\" * 50)\nprint(\"é…ç½®æ±‡æ€»\")\nprint(\"=\" * 50)\nprint(f\"è®¾å¤‡:         {DEVICE}\")\nprint(f\"æ™ºèƒ½ä½“:       {cfg.env.num_agents} x {cfg.env.formation_shape}\")\nprint(f\"åœºåœ°:         {cfg.env.arena_size} x {cfg.env.arena_size}\")\nprint(f\"å®‰å…¨åŠå¾„:     {cfg.safety.safety_radius}\")\nprint(f\"COSMOS æ¨¡å¼:  {COSMOS_MODE}\")\nprint(f\"è¾“å‡ºç›®å½•:     {OUTPUT_DIR}\")\nprint(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. åˆå§‹åŒ– WandB (å¯é€‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# åˆå§‹åŒ– WandB\nimport wandb\n\nif USE_WANDB:\n    wandb.init(\n        project=\"cosmos-formation-nav\",\n        name=f\"{EXPERIMENT_NAME}_{RUN_ID}\",\n        id=RUN_ID,\n        resume=\"allow\",  # æ”¯æŒæ–­ç‚¹ç»­è®­\n        config=config_dict,\n        tags=[FORMATION, f\"n{NUM_AGENTS}\", COSMOS_MODE],\n    )\n    # ä¿å­˜ä»£ç \n    wandb.run.log_code(\".\")\n    print(f\"âœ“ WandB åˆå§‹åŒ–æˆåŠŸ\")\n    print(f\"  é¡¹ç›®: cosmos-formation-nav\")\n    print(f\"  è¿è¡Œ: {wandb.run.name}\")\n    print(f\"  é“¾æ¥: {wandb.run.get_url()}\")\nelse:\n    print(\"è·³è¿‡ WandB (USE_WANDB=False)\")\n    print(\"è­¦å‘Š: è®­ç»ƒæ—¥å¿—å°†ä¸ä¼šä¿å­˜åˆ°äº‘ç«¯\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. åˆ›å»ºç¯å¢ƒå’Œæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç¯å¢ƒ\nenv = FormationNavEnv(cfg.env, cfg.reward)\ntopology = FormationTopology(cfg.env.num_agents, \"complete\")\n\n# COSMOS æ¨¡å¼\ncosmos_mode = COSMOSMode.CENTRALIZED if COSMOS_MODE == \"centralized\" else COSMOSMode.DECENTRALIZED\n\n# COSMOS å®‰å…¨æ»¤æ³¢å™¨\ncosmos = COSMOS(\n    env_cfg=cfg.env,\n    safety_cfg=cfg.safety,\n    desired_distances=env.desired_distances,\n    topology_edges=topology.edges(),\n    obstacle_positions=env.obstacles,\n    mode=cosmos_mode\n)\n\n# MAPPO\nobs_dim = env.observation_space.shape[0]\nshare_obs_dim = env.share_observation_space.shape[0]\n\nmappo = MAPPO(obs_dim, share_obs_dim, act_dim=2, cfg=cfg.algo, device=DEVICE)\n\n# Buffer\nbuffer = RolloutBuffer(\n    episode_length=cfg.env.max_steps,\n    num_agents=cfg.env.num_agents,\n    obs_dim=obs_dim,\n    share_obs_dim=share_obs_dim,\n    act_dim=2,\n    gamma=cfg.algo.gamma,\n    gae_lambda=cfg.algo.gae_lambda,\n    device=DEVICE\n)\n\n# æ–­ç‚¹ç»­è®­: åŠ è½½æ£€æŸ¥ç‚¹\nstart_episode = 0\nmetrics = {'episode': [], 'reward': [], 'cost': [], 'formation_error': [], 'min_dist': [], 'collisions': []}\n\nif RESUME_FROM_CHECKPOINT and os.path.exists(RESUME_FROM_CHECKPOINT):\n    print(f\"ä»æ£€æŸ¥ç‚¹æ¢å¤: {RESUME_FROM_CHECKPOINT}\")\n    checkpoint = torch.load(RESUME_FROM_CHECKPOINT, map_location=DEVICE)\n    # åŠ è½½æ¨¡å‹æƒé‡ (MAPPO å†…éƒ¨ç½‘ç»œ)\n    mappo.actor.load_state_dict(checkpoint['actor'])\n    mappo.critic.load_state_dict(checkpoint['critic'])\n    if 'cost_critic' in checkpoint:\n        mappo.cost_critic.load_state_dict(checkpoint['cost_critic'])\n    start_episode = checkpoint.get('episode', 0)\n    metrics = checkpoint.get('metrics', metrics)\n    print(f\"  å·²æ¢å¤åˆ° Episode {start_episode}\")\nelse:\n    print(\"ä»å¤´å¼€å§‹è®­ç»ƒ\")\n\nprint(f\"\\nè§‚æµ‹ç»´åº¦:    {obs_dim}\")\nprint(f\"å…±äº«è§‚æµ‹:    {share_obs_dim}\")\nprint(f\"COSMOS æ¨¡å¼: {cosmos_mode.value}\")\nprint(f\"è®¾å¤‡:        {DEVICE}\")\nprint(f\"èµ·å§‹è½®æ•°:    {start_episode}\")\nprint(\"\\nâœ“ åˆå§‹åŒ–å®Œæˆ!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# è®­ç»ƒå¾ªç¯ (æ”¯æŒæ–­ç‚¹ç»­è®­å’Œæ£€æŸ¥ç‚¹ä¿å­˜)\n\ndef save_checkpoint(episode, mappo, metrics, path):\n    \"\"\"ä¿å­˜æ£€æŸ¥ç‚¹ (ä¸ MAPPO.save() æ ¼å¼å…¼å®¹)\"\"\"\n    checkpoint = {\n        'episode': episode,\n        'actor': mappo.actor.state_dict(),\n        'critic': mappo.critic.state_dict(),\n        'cost_critic': mappo.cost_critic.state_dict(),\n        'metrics': metrics,\n        'config': config_dict,\n    }\n    torch.save(checkpoint, path)\n    return path\n\nprint(\"å¼€å§‹è®­ç»ƒ...\")\nprint(\"=\" * 70)\n\nstart_time = time.time()\ntotal_steps = 0\nLOG_INTERVAL = max(1, NUM_EPISODES // 10)\nbest_reward = float('-inf')\n\nfor episode in range(start_episode, NUM_EPISODES):\n    obs, share_obs, _ = env.reset(seed=cfg.train.seed + episode)\n    cosmos.update_obstacles(env.obstacles)\n    cosmos.reset(env.positions)\n    buffer.set_first_obs(obs, share_obs)\n    \n    ep_reward, ep_cost, ep_form_err, ep_min_dist, ep_collisions = 0.0, 0.0, 0.0, float('inf'), 0\n    \n    for step in range(cfg.env.max_steps):\n        alphas, log_probs = mappo.get_actions(obs)\n        values = mappo.get_values(share_obs)\n        safe_actions = cosmos.project(alphas, env.positions, env.velocities, dt=cfg.env.dt)\n        next_obs, next_share_obs, rewards, costs, dones, infos, _ = env.step(safe_actions)\n        \n        masks = (~dones).astype(np.float32).reshape(-1, 1)\n        buffer.insert(next_obs, next_share_obs, alphas, log_probs, values, rewards, costs, masks)\n        \n        obs, share_obs = next_obs, next_share_obs\n        total_steps += cfg.env.num_agents\n        \n        ep_reward += rewards[0, 0]\n        ep_cost += costs[0, 0]\n        ep_form_err += infos[0][\"formation_error\"]\n        ep_min_dist = min(ep_min_dist, infos[0][\"min_inter_dist\"])\n        ep_collisions += infos[0][\"collisions\"]\n        \n        if dones.all():\n            break\n    \n    # PPO æ›´æ–°\n    last_values = mappo.get_values(share_obs)\n    buffer.compute_returns_and_advantages(last_values)\n    update_info = mappo.update(buffer)\n    buffer.after_update()\n    \n    # è®°å½•æŒ‡æ ‡\n    avg_form_err = ep_form_err / (step + 1)\n    metrics['episode'].append(episode + 1)\n    metrics['reward'].append(ep_reward)\n    metrics['cost'].append(ep_cost)\n    metrics['formation_error'].append(avg_form_err)\n    metrics['min_dist'].append(ep_min_dist)\n    metrics['collisions'].append(ep_collisions)\n    \n    # WandB æ—¥å¿—\n    if USE_WANDB:\n        wandb.log({\n            \"train/reward\": ep_reward,\n            \"train/cost\": ep_cost,\n            \"train/formation_error\": avg_form_err,\n            \"train/min_inter_dist\": ep_min_dist,\n            \"train/collisions\": ep_collisions,\n            \"train/episode_length\": step + 1,\n            \"train/total_steps\": total_steps,\n            \"episode\": episode + 1,\n        })\n    \n    # ä¿å­˜æ£€æŸ¥ç‚¹\n    if (episode + 1) % SAVE_CHECKPOINT_EVERY == 0:\n        ckpt_path = f\"{CHECKPOINT_DIR}/checkpoint_ep{episode+1}.pt\"\n        save_checkpoint(episode + 1, mappo, metrics, ckpt_path)\n        print(f\"  [æ£€æŸ¥ç‚¹å·²ä¿å­˜: {ckpt_path}]\")\n        \n        # ä¸Šä¼ åˆ° WandB\n        if USE_WANDB:\n            artifact = wandb.Artifact(f\"checkpoint_ep{episode+1}\", type=\"model\")\n            artifact.add_file(ckpt_path)\n            wandb.log_artifact(artifact)\n    \n    # ä¿å­˜æœ€ä½³æ¨¡å‹\n    if ep_reward > best_reward:\n        best_reward = ep_reward\n        best_path = f\"{CHECKPOINT_DIR}/best_model.pt\"\n        save_checkpoint(episode + 1, mappo, metrics, best_path)\n    \n    # æ‰“å°è¿›åº¦\n    if (episode + 1) % LOG_INTERVAL == 0:\n        elapsed = time.time() - start_time\n        fps = total_steps / elapsed\n        print(f\"Ep {episode+1:4d}/{NUM_EPISODES} | R={ep_reward:7.2f} | Cost={ep_cost:4.0f} | \"\n              f\"FormErr={avg_form_err:.4f} | MinDist={ep_min_dist:.3f} | Coll={ep_collisions:2d} | FPS={fps:.0f}\")\n\n# ä¿å­˜æœ€ç»ˆæ¨¡å‹\nfinal_path = f\"{CHECKPOINT_DIR}/final_model.pt\"\nsave_checkpoint(NUM_EPISODES, mappo, metrics, final_path)\n\nelapsed = time.time() - start_time\nprint(\"=\" * 70)\nprint(f\"è®­ç»ƒå®Œæˆ! ç”¨æ—¶: {elapsed:.1f}s | æ€»ç¢°æ’: {sum(metrics['collisions'])}\")\nprint(f\"æ¨¡å‹å·²ä¿å­˜: {final_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. è®­ç»ƒæ›²çº¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# è®­ç»ƒæ›²çº¿ (ä¿å­˜åˆ°æ–‡ä»¶)\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\n\naxes[0, 0].plot(metrics['episode'], metrics['reward'], 'b-', alpha=0.7)\naxes[0, 0].set_title('Episode Reward')\naxes[0, 0].set_xlabel('Episode')\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(metrics['episode'], metrics['cost'], 'r-', alpha=0.7)\naxes[0, 1].set_title('Episode Cost')\naxes[0, 1].set_xlabel('Episode')\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[0, 2].plot(metrics['episode'], metrics['formation_error'], 'g-', alpha=0.7)\naxes[0, 2].set_title('Formation Error')\naxes[0, 2].set_xlabel('Episode')\naxes[0, 2].grid(True, alpha=0.3)\n\naxes[1, 0].plot(metrics['episode'], metrics['min_dist'], 'm-', alpha=0.7)\naxes[1, 0].axhline(y=cfg.safety.safety_radius, color='r', linestyle='--', label='Safety Radius')\naxes[1, 0].set_title('Min Inter-Agent Distance')\naxes[1, 0].set_xlabel('Episode')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\naxes[1, 1].plot(metrics['episode'], metrics['collisions'], 'c-', alpha=0.7)\naxes[1, 1].set_title('Collisions per Episode')\naxes[1, 1].set_xlabel('Episode')\naxes[1, 1].grid(True, alpha=0.3)\n\n# Smoothed reward\nwindow = min(20, len(metrics['episode']) // 5) or 1\nif window > 1:\n    smoothed = np.convolve(metrics['reward'], np.ones(window)/window, mode='valid')\n    axes[1, 2].plot(metrics['episode'][window-1:], smoothed, 'b-', linewidth=2)\nelse:\n    axes[1, 2].plot(metrics['episode'], metrics['reward'], 'b-', linewidth=2)\naxes[1, 2].set_title(f'Smoothed Reward (window={window})')\naxes[1, 2].set_xlabel('Episode')\naxes[1, 2].grid(True, alpha=0.3)\n\nplt.tight_layout()\n\n# ä¿å­˜åˆ°æ–‡ä»¶\ncurves_path = f\"{RESULTS_DIR}/training_curves.png\"\nplt.savefig(curves_path, dpi=150, bbox_inches='tight')\nprint(f\"è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {curves_path}\")\n\nplt.show()\n\n# ä¸Šä¼ åˆ° WandB\nif USE_WANDB:\n    wandb.log({\"charts/training_curves\": wandb.Image(fig)})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. è¯„ä¼°ä¸å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ¨¡å‹éªŒè¯ (å¤šæ¬¡è¯„ä¼°å¹¶ä¿å­˜ç»“æœ)\n\nNUM_EVAL_EPISODES = 10  # è¯„ä¼°è½®æ•°\neval_results = []\n\nprint(f\"å¼€å§‹éªŒè¯ ({NUM_EVAL_EPISODES} è½®)...\")\nprint(\"-\" * 50)\n\nfor eval_ep in range(NUM_EVAL_EPISODES):\n    obs, share_obs, _ = env.reset(seed=SEED + 1000 + eval_ep)\n    cosmos.update_obstacles(env.obstacles)\n    cosmos.reset(env.positions)\n    \n    trajectory = [env.positions.copy()]\n    ep_reward, ep_collisions, ep_form_err = 0.0, 0, 0.0\n    \n    for step in range(cfg.env.max_steps):\n        alphas, _ = mappo.get_actions(obs, deterministic=True)\n        safe_actions = cosmos.project(alphas, env.positions, env.velocities, dt=cfg.env.dt)\n        obs, share_obs, rewards, _, dones, infos, _ = env.step(safe_actions)\n        trajectory.append(env.positions.copy())\n        \n        ep_reward += rewards[0, 0]\n        ep_form_err += infos[0][\"formation_error\"]\n        ep_collisions += infos[0][\"collisions\"]\n        \n        if dones.all():\n            break\n    \n    # Convert numpy types to native Python types for JSON serialization\n    result = {\n        \"episode\": eval_ep + 1,\n        \"reward\": float(ep_reward),\n        \"collisions\": int(ep_collisions),\n        \"formation_error\": float(ep_form_err / (step + 1)),\n        \"steps\": step + 1,\n        \"min_dist\": float(infos[0][\"min_inter_dist\"]),\n    }\n    eval_results.append(result)\n    print(f\"Eval {eval_ep+1:2d}: R={ep_reward:7.2f} | Coll={ep_collisions} | FormErr={result['formation_error']:.4f}\")\n\n# ä¿å­˜æœ€åä¸€è½®çš„è½¨è¿¹ç”¨äºå¯è§†åŒ–\ntrajectory = np.array(trajectory)\nobstacles_pos = env.obstacles.copy()\ngoal_pos = env.goal.copy()\n\n# è®¡ç®—æ±‡æ€»ç»Ÿè®¡ (convert to Python float for JSON)\navg_reward = float(np.mean([r['reward'] for r in eval_results]))\navg_collisions = float(np.mean([r['collisions'] for r in eval_results]))\navg_form_err = float(np.mean([r['formation_error'] for r in eval_results]))\ntotal_collisions = sum([r['collisions'] for r in eval_results])\n\nprint(\"-\" * 50)\nprint(f\"å¹³å‡å¥–åŠ±:     {avg_reward:.2f}\")\nprint(f\"å¹³å‡ç¢°æ’:     {avg_collisions:.2f}\")\nprint(f\"æ€»ç¢°æ’æ•°:     {total_collisions}\")\nprint(f\"å¹³å‡ç¼–é˜Ÿè¯¯å·®: {avg_form_err:.4f}\")\n\n# ä¿å­˜éªŒè¯ç»“æœ\neval_results_path = f\"{RESULTS_DIR}/eval_results.json\"\nwith open(eval_results_path, 'w') as f:\n    json.dump({\n        \"results\": eval_results,\n        \"summary\": {\n            \"avg_reward\": avg_reward,\n            \"avg_collisions\": avg_collisions,\n            \"total_collisions\": total_collisions,\n            \"avg_formation_error\": avg_form_err,\n            \"num_episodes\": NUM_EVAL_EPISODES,\n        }\n    }, f, indent=2)\nprint(f\"\\néªŒè¯ç»“æœå·²ä¿å­˜: {eval_results_path}\")\n\n# ä¸Šä¼ åˆ° WandB\nif USE_WANDB:\n    wandb.log({\n        \"eval/avg_reward\": avg_reward,\n        \"eval/avg_collisions\": avg_collisions,\n        \"eval/total_collisions\": total_collisions,\n        \"eval/avg_formation_error\": avg_form_err,\n    })\n    \n    # ä¸Šä¼ ç»“æœæ–‡ä»¶\n    artifact = wandb.Artifact(\"eval_results\", type=\"results\")\n    artifact.add_file(eval_results_path)\n    wandb.log_artifact(artifact)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç»˜åˆ¶è½¨è¿¹å¹¶ä¿å­˜\nfig, ax = plt.subplots(figsize=(10, 10))\ncolors = plt.cm.tab10(np.linspace(0, 1, cfg.env.num_agents))\n\n# åœºåœ°è¾¹ç•Œ\nrect = patches.Rectangle((-cfg.env.arena_size, -cfg.env.arena_size), \n                          2*cfg.env.arena_size, 2*cfg.env.arena_size,\n                          linewidth=2, edgecolor='black', facecolor='none', linestyle='--')\nax.add_patch(rect)\n\n# éšœç¢ç‰©\nfor obs in obstacles_pos:\n    circle = patches.Circle((obs[0], obs[1]), obs[2], facecolor='gray', edgecolor='black', alpha=0.5)\n    ax.add_patch(circle)\n\n# ç›®æ ‡\nax.plot(goal_pos[0], goal_pos[1], 'r*', markersize=25, label='Goal')\n\n# è½¨è¿¹\nfor i in range(cfg.env.num_agents):\n    traj = trajectory[:, i, :]\n    ax.plot(traj[:, 0], traj[:, 1], '-', color=colors[i], alpha=0.7, linewidth=2)\n    ax.plot(traj[0, 0], traj[0, 1], 'o', color=colors[i], markersize=12, label=f'Agent {i}')\n    ax.plot(traj[-1, 0], traj[-1, 1], 's', color=colors[i], markersize=12)\n\n# æœ€ç»ˆç¼–é˜Ÿ\nfinal_pos = trajectory[-1]\nfor (i, j) in topology.edges():\n    ax.plot([final_pos[i, 0], final_pos[j, 0]], [final_pos[i, 1], final_pos[j, 1]], 'k--', alpha=0.5)\n\nax.set_xlim(-cfg.env.arena_size * 1.1, cfg.env.arena_size * 1.1)\nax.set_ylim(-cfg.env.arena_size * 1.1, cfg.env.arena_size * 1.1)\nax.set_aspect('equal')\nax.set_title('COSMOS + RMPflow + MAPPO Formation Navigation', fontsize=14)\nax.legend(loc='upper right')\nax.grid(True, alpha=0.3)\n\n# ä¿å­˜åˆ°æ–‡ä»¶\ntraj_path = f\"{RESULTS_DIR}/trajectory.png\"\nplt.savefig(traj_path, dpi=150, bbox_inches='tight')\nprint(f\"è½¨è¿¹å›¾å·²ä¿å­˜: {traj_path}\")\n\nplt.show()\n\n# ä¸Šä¼ åˆ° WandB\nif USE_WANDB:\n    wandb.log({\"charts/trajectory\": wandb.Image(fig)})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. åŠ¨ç”»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# åˆ›å»ºåŠ¨ç”»\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, cfg.env.num_agents))\n",
    "T = len(trajectory)\n",
    "\n",
    "def init():\n",
    "    ax.clear()\n",
    "    rect = patches.Rectangle((-cfg.env.arena_size, -cfg.env.arena_size), \n",
    "                              2*cfg.env.arena_size, 2*cfg.env.arena_size,\n",
    "                              linewidth=2, edgecolor='black', facecolor='none', linestyle='--')\n",
    "    ax.add_patch(rect)\n",
    "    for obs in obstacles_pos:\n",
    "        circle = patches.Circle((obs[0], obs[1]), obs[2], facecolor='gray', edgecolor='black', alpha=0.5)\n",
    "        ax.add_patch(circle)\n",
    "    ax.plot(goal_pos[0], goal_pos[1], 'r*', markersize=20)\n",
    "    ax.set_xlim(-cfg.env.arena_size * 1.1, cfg.env.arena_size * 1.1)\n",
    "    ax.set_ylim(-cfg.env.arena_size * 1.1, cfg.env.arena_size * 1.1)\n",
    "    ax.set_aspect('equal')\n",
    "    return []\n",
    "\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    init()\n",
    "    pos = trajectory[frame]\n",
    "    trail_start = max(0, frame - 30)\n",
    "    for i in range(cfg.env.num_agents):\n",
    "        trail = trajectory[trail_start:frame+1, i, :]\n",
    "        ax.plot(trail[:, 0], trail[:, 1], '-', color=colors[i], alpha=0.5, linewidth=2)\n",
    "        ax.plot(pos[i, 0], pos[i, 1], 'o', color=colors[i], markersize=12)\n",
    "    for (i, j) in topology.edges():\n",
    "        ax.plot([pos[i, 0], pos[j, 0]], [pos[i, 1], pos[j, 1]], 'k-', alpha=0.3)\n",
    "    ax.set_title(f'Step {frame}/{T-1}')\n",
    "    return []\n",
    "\n",
    "frames = list(range(0, T, max(1, T // 100)))\n",
    "anim = FuncAnimation(fig, update, init_func=init, frames=frames, blit=False, interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ˜¾ç¤ºåŠ¨ç”»\n",
    "from IPython.display import HTML\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. å®‰å…¨ç»Ÿè®¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æœ€ç»ˆç»Ÿè®¡ä¸ WandB å®Œæˆ\ntotal_train_collisions = sum(metrics['collisions'])\nsafe_episodes = sum(1 for c in metrics['collisions'] if c == 0)\n\nprint(\"=\" * 60)\nprint(\"COSMOS è®­ç»ƒä¸éªŒè¯æ±‡æ€»\")\nprint(\"=\" * 60)\nprint(f\"\\nã€è®­ç»ƒç»Ÿè®¡ã€‘\")\nprint(f\"  æ€»è½®æ•°:         {NUM_EPISODES}\")\nprint(f\"  æ€»ç¢°æ’æ¬¡æ•°:     {total_train_collisions}\")\nprint(f\"  é›¶ç¢°æ’è½®æ•°:     {safe_episodes}/{NUM_EPISODES} ({100*safe_episodes/NUM_EPISODES:.1f}%)\")\nprint(f\"  æœ€ç»ˆç¼–é˜Ÿè¯¯å·®:   {metrics['formation_error'][-1]:.4f}\")\nprint(f\"  æœ€ç»ˆæœ€å°è·ç¦»:   {metrics['min_dist'][-1]:.3f}\")\n\nprint(f\"\\nã€éªŒè¯ç»Ÿè®¡ã€‘\")\nprint(f\"  è¯„ä¼°è½®æ•°:       {NUM_EVAL_EPISODES}\")\nprint(f\"  å¹³å‡å¥–åŠ±:       {avg_reward:.2f}\")\nprint(f\"  å¹³å‡ç¢°æ’:       {avg_collisions:.2f}\")\nprint(f\"  å¹³å‡ç¼–é˜Ÿè¯¯å·®:   {avg_form_err:.4f}\")\n\nprint(f\"\\nã€ä¿å­˜æ–‡ä»¶ã€‘\")\nprint(f\"  è¾“å‡ºç›®å½•:       {OUTPUT_DIR}\")\nprint(f\"  æ£€æŸ¥ç‚¹ç›®å½•:     {CHECKPOINT_DIR}\")\nprint(f\"  ç»“æœç›®å½•:       {RESULTS_DIR}\")\n\n# åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„æ–‡ä»¶\nprint(f\"\\n  å·²ä¿å­˜çš„æ¨¡å‹:\")\nfor f in os.listdir(CHECKPOINT_DIR):\n    print(f\"    - {f}\")\n\nprint(\"=\" * 60)\n\n# å®Œæˆ WandB è¿è¡Œ\nif USE_WANDB:\n    # è®°å½•æœ€ç»ˆæ±‡æ€»\n    wandb.run.summary[\"train/total_collisions\"] = total_train_collisions\n    wandb.run.summary[\"train/safe_episode_rate\"] = safe_episodes / NUM_EPISODES\n    wandb.run.summary[\"eval/avg_reward\"] = avg_reward\n    wandb.run.summary[\"eval/total_collisions\"] = total_collisions\n    \n    # ä¸Šä¼ æ‰€æœ‰ç»“æœæ–‡ä»¶\n    artifact = wandb.Artifact(f\"results_{RUN_ID}\", type=\"results\")\n    artifact.add_dir(RESULTS_DIR)\n    wandb.log_artifact(artifact)\n    \n    # ä¸Šä¼ æœ€ç»ˆæ¨¡å‹\n    model_artifact = wandb.Artifact(f\"model_{RUN_ID}\", type=\"model\")\n    model_artifact.add_dir(CHECKPOINT_DIR)\n    wandb.log_artifact(model_artifact)\n    \n    wandb.finish()\n    print(\"\\nâœ“ WandB è¿è¡Œå·²å®Œæˆï¼Œæ‰€æœ‰æ•°æ®å·²ä¸Šä¼ \")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}